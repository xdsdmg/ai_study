\documentclass[letterpaper,11pt]{article}
\usepackage{CJKutf8}
\usepackage{bm}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage[cal=boondox]{mathalfa}

\geometry{a4paper,left=2cm,right=2cm,top=1cm,bottom=1cm}

\begin{document}
\begin{CJK}{UTF8}{gbsn}

\section{Linear regression}

乘以$\frac{1}{2}$是为了后续计算导数时能够刚好抵消。

$$h(x)=\sum_{i=0}^n{\theta}x_i=\bm{{\theta}^T}\bm{x}$$

$$J(\theta)=\frac{1}{2}\sum_{i=1}^n(h_{\theta}(x^{(i)})-y^{(i)})^2$$

目的是找到一个$\theta$使得$J(\theta)$的值最小。

\subsection{LMS algorithm}

梯度下降算法

$${\theta}_j:={\theta}_j-{\alpha}\frac{\partial}{{\partial}{\theta}_j}J(\theta)$$

$\alpha$为学习率

For these reasons, particularly when the training set is large, stochastic gradient descent is often preferred over batch gradient descent.

\subsection{The normal equations}

$$\nabla_{\theta}J(\theta)=X^TX{\theta}-X^T\bm{y}$$
$$\theta=(X^TX)^{-1}X^T\bm{y}$$

这里假设$X^TX$为可逆矩阵。

\subsection{Probabilistic interpretation}

$$y^{(i)}=\theta^Tx^{(i)}+\epsilon^{(i)}$$

$$p(y^{(i)}|x^{(i)};\theta)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})$$

$$L(\theta)=\prod_{i=1}^n{\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})}$$

找到一个$\theta$使得$L(\theta)$最大。

\begin{align*}
\mathcal{l}(\theta)&=\log L(\theta) \\
  &=\log \prod_{i=1}^n{\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})} \\
  &=\sum_{i=1}^n \log {\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2})} \\
  &=n \log \frac{1}{\sqrt{2\pi}\sigma} - \frac{1}{\sigma^2} \cdot \frac{1}{2} \sum_{i=1}^n(y^{(i)} - \theta^T x^{(i)})^2
\end{align*}

需要找到一个$\theta$最小化。

$$\frac{1}{2} \sum_{i=1}^n(y^{(i)} - \theta^T x^{(i)})^2$$

又得到了相同的结论。

\subsection{Locally weighted linear regression}

需要找到一个$\theta$最小化。

$$\sum_{i=1}^n w^{(i)} (y^{(i)} - \theta^T x^{(i)})^2$$

$$w^{(i)}=\exp \left(-\frac{(x^{(i)}-x)^2}{2\tau^2}\right)$$

越接近$x$，$w$越大。

\section{Logistic regression}

$$h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^T x}}$$

$$g(z)=\frac{1}{1+e^{-z}}$$

\subsection{Multi-class classification}

\end{CJK}
\end{document}



